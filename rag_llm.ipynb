{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовкка RAG системы\n",
    "\n",
    "Приступим к настройке RAG системы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, PromptTemplate\n",
    "from llama_index.core.embeddings import resolve_embed_model\n",
    "\n",
    "# import nest_asyncio\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME               ID              SIZE      MODIFIED    \n",
      "llama3.2:latest    a80c4f17acd5    2.0 GB    2 weeks ago    \n"
     ]
    }
   ],
   "source": [
    "! ollama list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем релизовтаь простой поисковик, который будет переводить документы в векторный формат который позвлит нам производить поиск по данным хранящимся в файле\n",
    "\n",
    "Попробуем реализовать бейзлайн RAG приложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm an artificial intelligence model known as Llama. Llama stands for \"Large Language Model Meta AI.\" It's a type of sequence-to-sequence model that uses self-attention mechanisms to process and generate human-like language. My primary function is to understand and respond to natural language inputs, providing information and assistance on a wide range of topics. I'm constantly learning and improving my responses based on user interactions like this one. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "# В первый раз ставим время побольше, чтобы модель установилась\n",
    "llm = Ollama(model=\"llama3.2:latest\", request_timeout=120.0)\n",
    "\n",
    "# llm.complete('Hello. How are you?')\n",
    "\n",
    "# Напишем запрос к модели\n",
    "prompt = \"\"\"\n",
    "Hello. Tell us what kind of model you are.\n",
    "\"\"\"\n",
    "mesage = llm.complete(prompt)\n",
    "\n",
    "print(mesage.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LlamaParse — это универсальный инструмент для подготовки данных для больших языковых моделей.\n",
    "\n",
    "[Основная цель LlamaParse — парсить и очищать ваши данные, гарантируя их хорошее качество перед передачей в любой последующий сценарий использования LLM, например, расширенный RAG.](https://docs.llamaindex.ai/en/stable/llama_cloud/llama_parse/)\n",
    "\n",
    "[Introducing LlamaCloud and LlamaParse](https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id be9c8b77-4c2d-448e-982b-8a5837b01f0c\n",
      "..."
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "parser = LlamaParse(result_type='markdown')\n",
    "\n",
    "file_extractor = {'.pdf': parser}\n",
    "\n",
    "# Смотрим директорию и ищем файлы в формате pdf\n",
    "documents = SimpleDirectoryReader(input_dir='./data', file_extractor=file_extractor).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\Documents\\GitHub\\llamaindex_RAG_MLLM\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Грузим модель для создания векторных эмбеддингов текста\n",
    "embed_model = resolve_embed_model('local:BAAI/bge-m3')\n",
    "# Создаём индекс векторов для эффективного поиска по коллекции документов\n",
    "vector_index = VectorStoreIndex.from_documents(documents, embed_model=embed_model)\n",
    "# Создаём \"движок запросов\" на основе созданного индекса векторов\n",
    "query_engine = vector_index.as_query_engine(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The existing work appears to be a grammar guide or textbook, covering various aspects of writing and language usage. The topics listed in the table of contents suggest that it covers subjects such as sentence structure, punctuation, verb tenses, and word choice, with a focus on clarity and effectiveness.\n"
     ]
    }
   ],
   "source": [
    "result = query_engine.query('Based on the existing table of contents, tell us what the existing work is about.')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем написать свой локальный поисковик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Запуск RAG локально (Подготовка)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка необходимых зависимостей\n",
    "# ! pip install weaviate-client sentence-transformers PyPDF2 sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запуск weaviate - локально\n",
    "# Для этого отдельно настроим ollama и weaviate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка готовкности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверка работоспособности weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"links\":[{\"href\":\"/v1/meta\",\"name\":\"Meta information about this instance/cluster\"},{\"documentationHref\":\"https://weaviate.io/developers/weaviate/api/rest#tag/schema/get/schema\",\"href\":\"/v1/schema\",\"name\":\"view complete schema\"},{\"documentationHref\":\"https://weaviate.io/developers/weaviate/api/rest#tag/schema/put/schema/{className}\",\"href\":\"/v1/schema{/:className}\",\"name\":\"CRUD schema\"},{\"documentationHref\":\"https://weaviate.io/developers/weaviate/api/rest#tag/objects/\",\"href\":\"/v1/objects{/:id}\",\"name\":\"CRUD objects\"},{\"documentationHref\":\"https://weaviate.io/developers/weaviate/api/rest#tag/classifications\",\"href\":\"/v1/classifications{/:id}\",\"name\":\"trigger and view status of classifications\"},{\"documentationHref\":\"https://weaviate.io/developers/weaviate/api/rest#tag/well-known/get/.well-known/live\",\"href\":\"/v1/.well-known/live\",\"name\":\"check if Weaviate is live (returns 200 on GET when live)\"},{\"documentationHref\":\"https://weaviate.io/developers/weaviate/api/rest#tag/well-known/get/.well-known/ready\",\"href\":\"/v1/.well-known/ready\",\"name\":\"check if Weaviate is ready (returns 200 on GET when ready)\"},{\"documentationHref\":\"https://weaviate.io/developers/weaviate/api/rest#tag/well-known/get/.well-known/openid-configuration\",\"href\":\"/v1/.well-known/openid-configuration\",\"name\":\"view link to openid configuration (returns 404 on GET if no openid is configured)\"}]}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  1383  100  1383    0     0   291k      0 --:--:-- --:--:-- --:--:--  337k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!curl -X GET http://127.0.0.1:8083/v1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверка работоспособности ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"version\":\"0.3.14\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100    20  100    20    0     0   5740      0 --:--:-- --:--:-- --:--:--  6666\n"
     ]
    }
   ],
   "source": [
    "!curl -X GET http://localhost:11437/api/version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка модели [qwen2.5](https://github.com/QwenLM/Qwen2.5?ysclid=m5fieixax7580998174)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"status\":\"pulling manifest\"}\n",
      "{\"status\":\"pulling c5396e06af29\",\"digest\":\"sha256:c5396e06af294bd101b30dce59131a76d2b773e76950acc870eda801d3ab0515\",\"total\":397807936,\"completed\":397807936}\n",
      "{\"status\":\"pulling 66b9ea09bd5b\",\"digest\":\"sha256:66b9ea09bd5b7099cbb4fc820f31b575c0366fa439b08245566692c6784e281e\",\"total\":68,\"completed\":68}\n",
      "{\"status\":\"pulling eb4402837c78\",\"digest\":\"sha256:eb4402837c7829a690fa845de4d7f3fd842c2adee476d5341da8a46ea9255175\",\"total\":1482,\"completed\":1482}\n",
      "{\"status\":\"pulling 832dd9e00a68\",\"digest\":\"sha256:832dd9e00a68dd83b3c3fb9f5588dad7dcf337a0db50f7d9483f310cd292e92e\",\"total\":11343,\"completed\":11343}\n",
      "{\"status\":\"pulling 005f95c74751\",\"digest\":\"sha256:005f95c7475154a17e84b85cd497949d6dd2a4f9d77c096e3c66e4d9c32acaf5\",\"total\":490,\"completed\":490}\n",
      "{\"status\":\"verifying sha256 digest\"}\n",
      "{\"status\":\"writing manifest\"}\n",
      "{\"status\":\"success\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100    54    0    30  100    24    934    747 --:--:-- --:--:-- --:--:--  1636\n",
      "100    54    0    30  100    24     24     19  0:00:01  0:00:01 --:--:--    44\n",
      "100    54    0    30  100    24     13     10  0:00:02  0:00:02 --:--:--    24\n",
      "100    54    0    30  100    24      9      7  0:00:03  0:00:03 --:--:--    16\n",
      "100    54    0    30  100    24      7      5  0:00:04  0:00:04 --:--:--    12\n",
      "100    54    0    30  100    24      5      4  0:00:06  0:00:05  0:00:01     0\n",
      "100   883    0   859  100    24    159      4  0:00:06  0:00:05  0:00:01   198\n"
     ]
    }
   ],
   "source": [
    "! curl http://localhost:11437/api/pull -d \"{\\\"name\\\": \\\"qwen2.5:0.5b\\\"}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка векторизатора [paraphrase-multilingual-minilm](https://ollama.com/nextfire/paraphrase-multilingual-minilm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"status\":\"pulling manifest\"}\n",
      "{\"status\":\"pulling 35812201e590\",\"digest\":\"sha256:35812201e590e2f5265c73f70c9a8a0e6ad951317872d66787d9a987bd919e6b\",\"total\":120942208,\"completed\":120942208}\n",
      "{\"status\":\"pulling cfc7749b96f6\",\"digest\":\"sha256:cfc7749b96f63bd31c3c42b5c471bf756814053e847c10f3eb003417bc523d30\",\"total\":11358,\"completed\":11358}\n",
      "{\"status\":\"pulling e700587efa15\",\"digest\":\"sha256:e700587efa156750d5e99d3336a27efcdf4687573351fa4f100a3d9022220361\",\"total\":16,\"completed\":16}\n",
      "{\"status\":\"pulling d643d3fca3bf\",\"digest\":\"sha256:d643d3fca3bf1ec11f2749b1f70be3048b8356c4a2c9bce253fadd28f8d09894\",\"total\":409,\"completed\":409}\n",
      "{\"status\":\"verifying sha256 digest\"}\n",
      "{\"status\":\"writing manifest\"}\n",
      "{\"status\":\"success\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100    81    0    30  100    51     24     41  0:00:01  0:00:01 --:--:--    66\n",
      "100   763    0   712  100    51    558     39  0:00:01  0:00:01 --:--:--   598\n"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:11437/api/pull -d \"{\\\"name\\\": \\\"nextfire/paraphrase-multilingual-minilm\\\"}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверка наличия моделей в ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"object\":\"list\",\"data\":[{\"id\":\"nextfire/paraphrase-multilingual-minilm:latest\",\"object\":\"model\",\"created\":1736157579,\"owned_by\":\"nextfire\"},{\"id\":\"qwen2.5:0.5b\",\"object\":\"model\",\"created\":1736157578,\"owned_by\":\"library\"}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   224  100   224    0     0   7115      0 --:--:-- --:--:-- --:--:--  7225\n"
     ]
    }
   ],
   "source": [
    "!curl -X GET http://localhost:11437/v1/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверка моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"model\":\"qwen2.5:0.5b\",\"created_at\":\"2025-01-06T09:59:45.656104507Z\",\"response\":\"The sky is typically blue because it reflects light that falls on it from the ground. The Earth's atmosphere consists of air and particles suspended in it, which refract and scatter light into different colors. When sunlight enters the atmosphere, some of the shorter wavelength blue wavelengths are scattered and reflected by tiny water droplets or ice crystals in the air, while longer wavelength red and yellow wavelengths are absorbed.\\n\\nThis scattering of light also causes the sky to appear blue because the Earth's surface is dark, reflecting a large portion of the sky as blue. Therefore, the sky appears to be composed primarily of blue colors when viewed from ground level, but in fact it has many shades of blue that can vary depending on the time of day and other atmospheric conditions.\",\"done\":true,\"done_reason\":\"stop\",\"context\":[151644,8948,198,2610,525,1207,16948,11,3465,553,54364,14817,13,1446,525,264,10950,17847,13,151645,198,151644,872,198,10234,374,279,12884,6303,30,151645,198,151644,77091,198,785,12884,374,11136,6303,1576,432,25963,3100,429,17066,389,432,504,279,4910,13,576,9237,594,16566,17167,315,3720,323,18730,21612,304,432,11,892,19353,531,323,44477,3100,1119,2155,7987,13,3197,39020,28833,279,16566,11,1045,315,279,23327,45306,6303,92859,525,36967,323,25911,553,13673,3015,6973,89492,476,9853,47373,304,279,3720,11,1393,5021,45306,2518,323,13753,92859,525,41001,382,1986,71816,315,3100,1083,11137,279,12884,311,4994,6303,1576,279,9237,594,7329,374,6319,11,41752,264,3460,13348,315,279,12884,438,6303,13,15277,11,279,12884,7952,311,387,23415,15503,315,6303,7987,979,19334,504,4910,2188,11,714,304,2097,432,702,1657,36099,315,6303,429,646,13289,11649,389,279,882,315,1899,323,1008,44375,4682,13],\"total_duration\":5569400735,\"load_duration\":3147873794,\"prompt_eval_count\":35,\"prompt_eval_duration\":161379000,\"eval_count\":150,\"eval_duration\":2205233000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100    77    0     0  100    77      0     63  0:00:01  0:00:01 --:--:--    63\n",
      "100    77    0     0  100    77      0     34  0:00:02  0:00:02 --:--:--    34\n",
      "100    77    0     0  100    77      0     23  0:00:03  0:00:03 --:--:--    23\n",
      "100    77    0     0  100    77      0     18  0:00:04  0:00:04 --:--:--    18\n",
      "100    77    0     0  100    77      0     14  0:00:05  0:00:05 --:--:--    14\n",
      "100  2042  100  1965  100    77    352     13  0:00:05  0:00:05 --:--:--   451\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST http://localhost:11437/api/generate -d \"{\\\"model\\\": \\\"qwen2.5:0.5b\\\", \\\"prompt\\\": \\\"Why is the sky blue?\\\", \\\"stream\\\": false }\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"embedding\":[0.10243025422096252,0.1631552129983902,-0.0017925690626725554,0.019952569156885147,-0.40203267335891724,-0.25778889656066895,0.47496065497398376,0.0986882895231247,0.15451876819133759,0.010218325071036816,0.236474871635437,-0.6180628538131714,0.34798306226730347,0.05890214815735817,0.20767325162887573,-0.10691619664430618,-0.06268472224473953,0.004951045848429203,-0.2662738859653473,-0.10864783823490143,0.12152256071567535,-0.2818492352962494,-0.21320945024490356,-0.026707563549280167,0.06072978302836418,-0.15678583085536957,-0.13536374270915985,0.10134082287549973,0.22149130702018738,-0.029317112639546394,0.2582590579986572,0.17505118250846863,0.11067056655883789,0.227215975522995,0.07117859274148941,0.2038756161928177,0.008976750075817108,-0.11290179193019867,0.13869039714336395,0.1382545828819275,-0.30882781744003296,-0.014258010312914848,0.1120598092675209,0.46466097235679626,0.03717806935310364,0.1566106528043747,-0.05410315468907356,-0.11345037817955017,0.3638498783111572,0.09988123178482056,0.08749707043170929,-0.19489052891731262,-0.4122335910797119,0.05099334940314293,0.17930741608142853,-0.03654167428612709,0.3219601809978485,-0.024791335687041283,-0.18236497044563293,0.3396180272102356,0.09841040521860123,0.04882350564002991,-0.750192403793335,0.08581569790840149,-0.5396722555160522,0.09684477001428604,0.10947263985872269,-0.12561865150928497,-0.011564879678189754,0.2822040915489197,-0.08529391884803772,-0.11174921691417694,0.226107656955719,0.16585296392440796,0.2459244579076767,-0.13482826948165894,0.16183026134967804,-0.030344415456056595,-0.10770740360021591,0.14274883270263672,0.3272261917591095,-0.038894493132829666,-0.004819769877940416,0.1386207938194275,0.07079262286424637,0.1027904599905014,0.18148764967918396,0.18275874853134155,0.3105997145175934,-0.14324231445789337,0.07070017606019974,-0.10809209197759628,0.10627757757902145,0.09593554586172104,0.11982475966215134,-0.014208259992301464,0.0423593707382679,-0.2766224145889282,0.1540006548166275,1.7499712705612183,0.05982744321227074,0.1161489337682724,-0.05287636071443558,0.2008822113275528,-0.12112022936344147,0.07140332460403442,0.10167942941188812,0.09631358832120895,0.02482040971517563,-0.10889365524053574,-0.18792900443077087,-0.2430649846792221,-0.17652854323387146,0.002547843847423792,-0.12045038491487503,0.07726513594388962,-0.15064699947834015,-0.08594608306884766,-0.08992171287536621,-0.017347699031233788,0.055536579340696335,-0.03666256368160248,-0.21637918055057526,-0.07980428636074066,0.242137610912323,-0.7045366764068604,0.14100071787834167,-0.037563130259513855,0.16277329623699188,0.2608218193054199,0.12069004774093628,0.02156873606145382,0.180337592959404,0.27139589190483093,-0.2508031725883484,-0.0972740650177002,0.09874564409255981,0.08646336942911148,-0.12859025597572327,-0.20468473434448242,-0.26279783248901367,0.11851106584072113,-0.12151869386434555,-0.021287253126502037,0.08423516899347305,0.2084135264158249,-0.2268752008676529,-0.02913764677941799,0.13037212193012238,0.028634486719965935,0.21864618360996246,-0.17456698417663574,0.012683880515396595,0.2306191325187683,0.03452451899647713,-0.09045720845460892,0.2291182428598404,0.11302056908607483,0.004357919096946716,0.03276979178190231,-0.17594122886657715,0.08213087916374207,-0.025366876274347305,-0.4695552587509155,0.1365639865398407,-0.20613320171833038,-0.07296795397996902,0.03532581031322479,-0.04183745011687279,0.16030041873455048,-0.23351329565048218,0.022097747772932053,0.29654258489608765,0.27028992772102356,0.060443177819252014,-0.006845007184892893,-0.05587875097990036,-0.19339562952518463,-0.33534061908721924,0.005083195865154266,-0.007849167101085186,0.3356991112232208,0.009714600630104542,0.1301286816596985,-0.07813143730163574,0.032296326011419296,-0.2752252519130707,-0.060264527797698975,0.08534549176692963,-0.295734167098999,-0.04974101111292839,-0.1251346617937088,-0.10671548545360565,-0.2688424289226532,-0.08234883099794388,-0.2608133554458618,0.03904147818684578,-0.12939384579658508,0.016619287431240082,0.09281224757432938,-0.3281877338886261,0.07053361088037491,-0.18948157131671906,-0.3590810000896454,0.1982192099094391,-0.04021865501999855,0.24636322259902954,-0.06574462354183197,-0.36987319588661194,0.07189496606588364,-0.14633461833000183,-0.05849059298634529,0.09940540790557861,0.11003052443265915,0.07460182905197144,-0.15055394172668457,-0.025582700967788696,-0.04608478397130966,-0.6797548532485962,0.004335668869316578,0.2836260497570038,-0.46270662546157837,-0.18780478835105896,-0.7652071714401245,0.25141873955726624,0.010394622571766376,-0.3102022707462311,-0.34162864089012146,-0.3701446056365967,-0.2820848524570465,0.03656554967164993,0.35036513209342957,0.35959863662719727,0.2062121480703354,-0.12580610811710358,0.024220164865255356,0.06675054877996445,0.008213590830564499,-0.09999984502792358,-0.40926963090896606,0.3432518243789673,-0.0410853773355484,-0.18699350953102112,0.17419925332069397,-0.01806918904185295,-0.1969243586063385,-0.3955252170562744,0.3605058789253235,-0.20582552254199982,0.7332583665847778,0.2602841556072235,-0.19370687007904053,-0.17269161343574524,0.12795861065387726,0.05531661584973335,0.12803055346012115,0.042897846549749374,0.051462724804878235,0.01168854907155037,-0.03907528147101402,0.3050400912761688,-0.025342613458633423,-0.41930457949638367,0.020284470170736313,0.20761114358901978,-0.07737304270267487,-0.00483789062127471,0.47237521409988403,-0.06905557215213776,-0.07223653793334961,-0.12553849816322327,-0.11524547636508942,0.09641262888908386,-0.24148766696453094,0.21918365359306335,-0.26297107338905334,0.3820079267024994,-0.09224750101566315,0.11980840563774109,0.1737179309129715,-0.20424224436283112,-0.3082316815853119,-0.03860296308994293,0.024159478023648262,-0.02442477084696293,-0.05085747316479683,-0.059879377484321594,0.28596073389053345,-0.05594412609934807,0.06651724129915237,0.035234566777944565,0.10246027261018753,0.11194045841693878,0.08265930414199829,0.12463878095149994,-0.1067703515291214,-0.10311365127563477,0.28779640793800354,-0.13469690084457397,0.14254368841648102,-0.03786454722285271,-0.13176414370536804,-0.050206661224365234,-0.20383234322071075,0.14590173959732056,-0.26210707426071167,-0.07575736194849014,-0.021208196878433228,0.39926353096961975,-0.40583547949790955,0.19429072737693787,0.16621363162994385,0.21341294050216675,-0.011776520870625973,-0.062580905854702,0.46037667989730835,-0.06628627330064774,0.08203694969415665,-0.03220919892191887,-0.973258912563324,-0.05667883902788162,-0.14568907022476196,-0.2205658257007599,0.15950942039489746,0.2644471228122711,-0.06621209532022476,0.048366159200668335,-0.5010128617286682,0.17342223227024078,-0.11715267598628998,-0.13902892172336578,0.14189310371875763,-0.20225174725055695,-0.23721885681152344,0.08400505781173706,0.3648216128349304,-0.2093798816204071,-0.07434646040201187,-0.055874183773994446,0.14902792870998383,-0.06396395713090897,0.3380392789840698,-0.24450379610061646,-0.14167477190494537,-0.13785091042518616,-0.06354405730962753,-0.14771459996700287,-0.20558814704418182,0.025606103241443634,0.18466228246688843,0.016467826440930367,0.06329290568828583,-0.11782308667898178,-0.19893822073936462,-0.4881870448589325,0.37763720750808716,0.11794339865446091,-0.025871189311146736,0.4255552589893341,-0.20886462926864624,0.5085862874984741,-0.03576135262846947,-0.025430714711546898,0.6218920350074768,-0.006374378222972155,0.030446726828813553,0.029210718348622322,-0.0030300908256322145,0.02846783585846424,0.10663270950317383,-0.26591596007347107,0.016758574172854424,-0.030848564580082893,-0.04324101284146309,-0.0407627709209919,-0.12176021933555603,0.006135884206742048,0.11341792345046997,-0.29610082507133484,0.18256092071533203,0.5423001646995544,-0.23651641607284546,0.2195485532283783,0.052544981241226196]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  7957    0  7850  100   107   7008     95  0:00:01  0:00:01 --:--:--  7104\n",
      "100  7957    0  7850  100   107   7007     95  0:00:01  0:00:01 --:--:--  7104\n"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:11437/api/embeddings -d \"{ \\\"model\\\": \\\"nextfire/paraphrase-multilingual-minilm\\\", \\\"prompt\\\": \\\"Llamas are members of the camelid family\\\"}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка и предподготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут у нас есть два пути\n",
    "Мы можем использовать *LangChain* и *LlamaIndex*\n",
    "В нашем случае - мы будем использовать *LangChain*, тк проект учебный и рассматриваемый фреймворк представляет нам возможность быстро получить необходимый результат\n",
    "\n",
    "***! Важная ремарка***:\n",
    "LlamaIndex позволяет более тонко настроить индексацию и поиск по векторной базе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\Documents\\GitHub\\llamaindex_RAG_MLLM\\.venv\\Lib\\site-packages\\PyPDF2\\__init__.py:21: DeprecationWarning: PyPDF2 is deprecated. Please move to the pypdf library instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Импорт библиотек\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import weaviate\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к папке с PDF файлами\n",
    "DATA_DIR = \"./data\"\n",
    "# Подключение к weaviate\n",
    "client = weaviate.connect_to_local(port=8083, grpc_port=50051)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для чтения файлов с директории\n",
    "def read_pdfs_from_folder(folder_path:str = \"./data\") -> pd.DataFrame:\n",
    "    \"\"\"Функция которая читает данные с выбранной директории\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Директория содержащая файлы в формате .pdf\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Прочтённые файлы\n",
    "    \"\"\"\n",
    "    \n",
    "    pdf_texts = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.pdf'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            reader = PdfReader(file_path)\n",
    "            text = ''\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text()\n",
    "            pdf_texts.append({'file_name': file_name, 'text': text})\n",
    "    # return pdf_texts\n",
    "    return pd.DataFrame(pdf_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rebecca_Elliott_-_Painless_Grammar_1997.pdf</td>\n",
       "      <td>cover next page &gt; \\n \\ntitle:\\nauthor:\\npublis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>А-05м-23 Гольцов МН КП_v1.pdf</td>\n",
       "      <td>Федеральное государственное бюджетное образова...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Лабораторная работа_Руководство FPTL.pdf</td>\n",
       "      <td>Федеральное государственное бюджетное образова...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     file_name  \\\n",
       "0  Rebecca_Elliott_-_Painless_Grammar_1997.pdf   \n",
       "1                А-05м-23 Гольцов МН КП_v1.pdf   \n",
       "2     Лабораторная работа_Руководство FPTL.pdf   \n",
       "\n",
       "                                                text  \n",
       "0  cover next page > \\n \\ntitle:\\nauthor:\\npublis...  \n",
       "1  Федеральное государственное бюджетное образова...  \n",
       "2  Федеральное государственное бюджетное образова...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Прочитаем данные из папки\n",
    "data = read_pdfs_from_folder(DATA_DIR)\n",
    "# # Сохраним данные в формате parquet\n",
    "# pd.DataFrame(data).to_parquet(os.path.join(DATA_DIR, \"data.parquet\"))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_documents(data: pd.DataFrame) -> List[Document]:\n",
    "    docs = [\n",
    "        Document(\n",
    "            page_content=row[\"text\"],\n",
    "            metadata={\n",
    "                \"doc_id\": row[\"file_name\"],\n",
    "            }\n",
    "        )\n",
    "        for _, row in data.iterrows()\n",
    "    ]\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Читаем файлы с помощью langchain_core.documents\n",
    "docs = create_documents(data=data)\n",
    "\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Предобработка документов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть два варианта как можно предобработать документы\n",
    " - Предобработать до разбиения\n",
    " - Предобработать после разбиения\n",
    "\n",
    "Рассмотрим оба варианта, их плюсы и минусы:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Предобработка ДО разбиения:\n",
    "Это значит, что мы сначала 'чистим' или изменяем текст документа, а потом делим его на кусочки, для обработки  \n",
    "\n",
    "Предобработка включает такие шаги:\n",
    " - удаление лишних пробелов, символов, HTML-тегов\n",
    " - приведение текста к нижнему регистру (например: 'Привет' -> 'привет')\n",
    " - удаление стоп-слов (например: 'и', 'в', 'на')\n",
    " - замена сокращений (например: 'т.к.' -> 'так как')\n",
    " - исправление опечаток \n",
    "\n",
    "**Плюсы**  \n",
    "1) *Еднообразие текста*: Все части текста будут обработаны одинаково, и мы избежим несоответствий  \n",
    "2) *Экономия времени*: Предобработка выполняется один раз для всего документа, а не для каждого кусочка  \n",
    "3) *Упрощение анализа*: Если текст нужно лемматизировать (привести слова к начальной форме), это легче сделать до разбиения  \n",
    "\n",
    "**Минусы**  \n",
    "1) *Проблемы с контекстом*: Предобработка может удалить важные слова, а это может исказить смысл  \n",
    "2) *Невозможность адаптации*: Если разные куски текста требуюи разной обработки общий подход может не подойти  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Предобработка ПОСЛЕ разбиения:\n",
    "Здесь мы сначала делим текст на кусочки, а потом каждый кусочек обрабатываем отдельно   \n",
    "\n",
    "**Плюсы**  \n",
    "1) *Гибкость*: Можно применять разные подходы к разным кусочкам  \n",
    "***Пример -> Для технического текста можно удалить формулы, а для описания - оставить***\n",
    "2) *Меньше ошибок с контекстом*: Разбиение сохраняет структуру текста, и мы можем обрабатывать кусочки, учитывая их содержимое  \n",
    "***Пример -> Если в одном кусочке есть дата, а в другом - событие, мы обработаем их отдельно и не потеряем смысл***  \n",
    "3) *Локальная оптимизация*: Можно обрабатывать только те кусочки, которые важны для задачи  \n",
    "***Пример -> Если часть текста не нужна, её можно исключить***  \n",
    "\n",
    "**Минусы**  \n",
    "1) *Больше ресурсов*: Каждый кусочек обрабатывается отдельно, что может занять больше времени и памяти  \n",
    "2) *Потеря глобального контекста*: Если предобработка зависит от всей структуры текста, разбиение может её нарушить  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Пример для наглядности\n",
    "\n",
    "Приведём приммер исходного текста - \"Компания Apple представила новый iPhone. Цена на него составит $999. Это вызвало бурные обсуждения в социальных сетях.\"\n",
    "\n",
    "**Предобработка ДО разбиения**  \n",
    "1) Удаляем знаки пунктуации  \n",
    "        *\"Компания Apple представила новый iPhone Цена на него составит 999 Это вызвало бурные обсуждения в социальных сетях\"*  \n",
    "2) Приводим к нижнему регистру  \n",
    "        *\"компания apple представила новый iphone цена на него составит 999 это вызвало бурные обсуждения в социальных сетях\"*  \n",
    "\n",
    "3) Разбиваем на кусочки  \n",
    " - *\"компания apple представила новый iphone\"*   \n",
    " - *\"цена на него составит 999\"*  \n",
    " - *\"это вызвало бурные обсуждения в социальных сетях\"*  \n",
    "\n",
    "**Предобработка ПОСЛЕ разбиения**\n",
    "1) Сначала делим текст на кусочки\n",
    " - \"Компания Apple представила новый iPhone.\"\n",
    " - \"Цена на него составит $999.\"\n",
    " - \"Это вызвало бурные обсуждения в социальных сетях.\"\n",
    "2) Обрабатываем каждый кусочек\n",
    " - \"компания apple представила новый iphone\"\n",
    " - \"цена на него составит 999\"\n",
    " - \"это вызвало бурные обсуждения в социальных сетях\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**  \n",
    " - Если текст гомогенный (однотипный), например, техническая документация, то лучше предобрабатывать ДО разбиения  \n",
    " - Если текст разнообразный (содержит разные стили и форматы), то предобработка ПОСЛЕ разбиения даст больше гибкости  \n",
    "\n",
    "*Для RAG-системы часто используется предобработка после разбиения, чтобы сохранить максимальный контекст в каждом кусочке*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разбиение документов на куски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В нашем случае тексты разбиты на логические блоки с помощью \\n\n",
    "# Но символ \\n встречается очень часто, и разбивать текст по ним не имеет смысл\n",
    "# Причиной этому является - слишком маленькие блоки получающиеся в результате разбиения, в дальнеёшем нам будет сложно искать и отвечать\n",
    "\n",
    "def split_document(docs: List[Document],\n",
    "                   chunk_size: int = 512, # 512\n",
    "                   chunk_overlap: int = 256, # 256 \n",
    "                   is_separator_regex: bool = False # \n",
    "                   ) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Разбивает текст документов на небольшие части для удобства обработки, поиска и анализа.\n",
    "\n",
    "    Args:\n",
    "        docs (List[Document]): Список объектов `Document`, содержащих текст и метаданные.\n",
    "        chunk_size (int): Максимальный размер одного фрагмента текста (в символах). \n",
    "                          По умолчанию 512.\n",
    "        chunk_overlap (int): Количество символов, которые перекрываются между соседними фрагментами.\n",
    "                             Это помогает сохранить контекст между частями. По умолчанию 256.\n",
    "        is_separator_regex (bool): Указывает, является ли разделитель регулярным выражением.\n",
    "                                   Если False, используется обычный строковый разделитель. По умолчанию False.\n",
    "\n",
    "    Returns:\n",
    "        List[Document]: Список объектов `Document`, содержащих нарезанные части текста.\n",
    "                        Каждая часть сохраняет оригинальные метаданные.\n",
    "\n",
    "    Пример использования:\n",
    "        documents = [\n",
    "            Document(page_content=\"Большой текст, который нужно разбить\", metadata={\"doc_id\": \"1\"})\n",
    "        ]\n",
    "        split_docs = split_document(documents, chunk_size=256, chunk_overlap=128)\n",
    "    \"\"\"\n",
    "    splitter = CharacterTextSplitter(\n",
    "        # Рассматриваемые тексты имеют разную структуру и мы не можем корректно указать какой из разделителей нужно использовать\n",
    "        # Поэтому попробуем просто разделить текст по символам\n",
    "        separator='',                      \n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        is_separator_regex=is_separator_regex,\n",
    "    )\n",
    "    return splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем исходные данные\n",
    "print(f\"Исходное количество документов: {len(docs)}\")\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"Документ {i}: длина текста = {len(doc.page_content)} символов\")\n",
    "\n",
    "split_docs = split_document(docs=docs)\n",
    "# Проверяем результат\n",
    "print(f\"Количество кусков после разбиения: {len(split_docs)}\")\n",
    "for i, doc in enumerate(split_docs):\n",
    "    # print(f\"Кусок {i}: {doc.page_content[:50]}... (длина: {len(doc.page_content)})\")\n",
    "    print(f\"Кусок {i}: длина куска: {len(doc.page_content)})\")\n",
    "\n",
    "# Исходное количество документов: 3\n",
    "# Документ 0: длина текста = 308153 символов\n",
    "# Документ 1: длина текста = 12084 символов\n",
    "# Документ 2: длина текста = 55970 символов\n",
    "# Количество кусков после разбиения: 1468"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Постобработка документов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Максимально распишем следующую ячейку:\n",
    "\n",
    "Мы будем использовать модуль re (регулярные выражения)\n",
    "\n",
    "- Создаем реглярное выражение для поиска последовательнсотей символов\n",
    "    - \\n - перевод строки  \n",
    "    - \\t - табуляции  \n",
    "    - \\r - возврат каретки  \n",
    "```python\n",
    "    TABS_REGEXP_TEXT = r'[\\n\\t\\r]+'\n",
    "```\n",
    "\n",
    "- Создаем реглярное выражение для поиска HTML-тегов\n",
    "\n",
    "```python\n",
    "    TAGS_REGEXP_TEXT = r'(\\<(/?[^>]+)>)'\n",
    "```\n",
    "\n",
    "- Создаем регулярное выражение для поиска всех символов, которые не являются латинскими буквами (a-z), кириллическими буквами (а-я) или цифрами (0-9)\n",
    "\n",
    "```python\n",
    "    SYMBOLS_REGEXP_TEXT = r'[^a-zа-я0-9]'\n",
    "    SYMBOLS_WITHDASH_REGEXP_TEXT = r'(\\s\\-\\s)|(\\-\\s)|(\\s\\-)|([^a-zа-я0-9\\-])'\n",
    "```\n",
    "\n",
    "- Создаем регулярное выражение для поиска последовательностей из одного или более пробельных символов \n",
    "\n",
    "```python\n",
    "    SPACES_REGEXP_TEXT = r\"\\s+\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "TABS_REGEXP_TEXT = r'[\\n\\t\\r]+'\n",
    "TAGS_REGEXP_TEXT = r'(\\<(/?[^>]+)>)'\n",
    "SYMBOLS_REGEXP_TEXT = r'[^a-zа-я0-9]'\n",
    "SYMBOLS_WITHDASH_REGEXP_TEXT = r'(\\s\\-\\s)|(\\-\\s)|(\\s\\-)|([^a-zа-я0-9\\-])'\n",
    "SPACES_REGEXP_TEXT = r\"\\s+\"\n",
    "\n",
    "TABS_REGEXP = re.compile(TABS_REGEXP_TEXT)\n",
    "TAGS_REGEXP = re.compile(TAGS_REGEXP_TEXT)\n",
    "SYMBOLS_REGEXP = re.compile(SYMBOLS_REGEXP_TEXT)\n",
    "SYMBOLS_WITHDASH_REGEXP = re.compile(SYMBOLS_WITHDASH_REGEXP_TEXT)\n",
    "SPACES_REGEXP = re.compile(SPACES_REGEXP_TEXT)\n",
    "\n",
    "\n",
    "def text_clean(text: str, keep_dash: bool = False) -> str:\n",
    "    \"\"\"Очистка текста\n",
    "\n",
    "    Args:\n",
    "        text (str): Исходный текст\n",
    "        keep_dash (bool, optional): Определяем, нужно ли сохранить дефисы в тексте\n",
    "\n",
    "    Returns:\n",
    "        str: Очищенную строку\n",
    "    \"\"\"\n",
    "    result = str(text)\n",
    "    result = result.lower()\n",
    "    result = result.replace(\"ё\", \"е\")\n",
    "    result = TABS_REGEXP.sub(\" \", result)\n",
    "    result = TAGS_REGEXP.sub(\" \", result)\n",
    "    if keep_dash:\n",
    "        result = SYMBOLS_WITHDASH_REGEXP.sub(\" \", result)\n",
    "    else:\n",
    "        result = SYMBOLS_REGEXP.sub(\" \", result)\n",
    "    result = result.strip()\n",
    "    result = SPACES_REGEXP.sub(\" \", result)    \n",
    "    return result\n",
    "\n",
    "def postprocess(docs: List[Document], keep_dash: bool = False) -> List[Document]:\n",
    "    \"\"\"Постобработка кусков текста\n",
    "\n",
    "    Args:\n",
    "        docs (List[Document]): Нарезанныен куски текста\n",
    "        keep_dash (bool, optional): Определяем, нужно ли сохранить дефисы в тексте\n",
    "\n",
    "    Returns:\n",
    "        List[Document]: Очищенные куски текста\n",
    "    \"\"\"\n",
    "    for doc in docs:\n",
    "        doc.page_content = text_clean(doc.page_content)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'doc_id': 'Rebecca_Elliott_-_Painless_Grammar_1997.pdf'}, page_content='cover next page title author publisher isbn10 asin print isbn13 ebook isbn13 language subject publication date lcc ddc subject cover next page page i painless grammar rebecca elliott ph d illustrated by laurie hamilton page ii copyright 1997 by rebecca elliott illustrations copyright 1997 by barron s educational series inc all rights reserved no part of this book'),\n",
       " Document(metadata={'doc_id': 'Rebecca_Elliott_-_Painless_Grammar_1997.pdf'}, page_content='trated by laurie hamilton page ii copyright 1997 by rebecca elliott illustrations copyright 1997 by barron s educational series inc all rights reserved no part of this book may be reproduced in any form by photostat microfilm xerography or any other means or incorporated into any information retrieval system electronic or m echanical without the written permission of the copyright owner all inquiries should be add')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs = postprocess(split_docs)\n",
    "\n",
    "split_docs[:2]\n",
    "# split_docs[1300:1302]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизация основывается на преобразовании объектов в многомерное пространство. В этом пространстве каждый объект представляется вектором, а расстояние между векторами отражает степень их сходства.\n",
    "\n",
    "Так, нам необходимо с помощью эмбедера получить векторное представление для загруженных документов. Поскольку в будущем мы будем осуществлять поиск по близости с помощью получившихся векторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "# from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "# from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(docs:List[Document],\n",
    "              host: str = \"http://localhost:11437\", \n",
    "              model_name: str = \"nextfire/paraphrase-multilingual-minilm\", \n",
    "              path_to_vectors: str = \"data/embeddings.npy\"\n",
    "              ) -> List[List[float]]:\n",
    "    \"\"\"Генерирует эмбеддинги из входных документов и сохраняет их в файл\n",
    "\n",
    "    Args:\n",
    "        docs (List[Document]): Список документов\n",
    "        host (str): Адрес на котором работает векторизатор\n",
    "        model_name (str): Название модели в нашем случае -- \"nextfire/paraphrase-multilingual-minilm\".\n",
    "        path_to_vectors (str): Путь для сохранения эмбеддингов\n",
    "\n",
    "    Returns:\n",
    "        List[List[float]]: Список эмбеддингов, где каждый эмбеддинг соответствует одному документу\n",
    "    \"\"\"\n",
    "        \n",
    "    embed_model = OllamaEmbeddings(model=model_name, base_url=host)\n",
    "    # embed_model = OllamaEmbedding(model_name=model_name, base_url=host)\n",
    "    \n",
    "    embeddings = embed_model.embed_documents(\n",
    "    # embeddings = embed_model.get_text_embedding_batch(\n",
    "        [\n",
    "            doc.page_content for doc in docs\n",
    "        ]\n",
    "    )\n",
    "    np.save(\n",
    "        file=path_to_vectors,\n",
    "        arr=embeddings\n",
    "    )\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обрабатываем наши тексты\n",
    "embeddings_docs = vectorize(docs=split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1468"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Настройка поискового движка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поисковой движок в RAG — это компонент, отвечающий за поиск релевантной информации в базе данных или хранилище знаний, чтобы дополнить генеративную модель контекстом для точного ответа\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем использовать два типа поиска:\n",
    "- Векторный -- *Ищет документы на основе их смыслового сходства. Запрос и документы преобразуются в векторы, а затем сравниваются по близости (например, с помощью косинусного расстояния). Используется для поиска по смыслу*\n",
    "\n",
    "\n",
    "- Полнотекстовый -- *Ищет документы по ключевым словам и фразам, учитывая точное совпадение текста. Подходит для поиска конкретных терминов или выражений*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource module not available on Windows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\Documents\\GitHub\\llamaindex_RAG_MLLM\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import weaviate\n",
    "import weaviate.classes.config as wc\n",
    "from bm25s.stopwords import STOPWORDS_RUSSIAN\n",
    "from weaviate.collections.classes.config import StopwordsPreset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_search_engine(\n",
    "    port: str = '8083',\n",
    "    grpc_port: str = '50051',\n",
    "    \n",
    "    mapping_types = {\n",
    "        \"doc_id\": wc.DataType.TEXT,  # Уникальный идентификатор документа\n",
    "        \"text\": wc.DataType.TEXT     # Основной текст документа\n",
    "    }\n",
    ") -> bool:\n",
    "    \"\"\"Настраивает поисковый движок с использованием Weaviate, \n",
    "    создавая коллекцию для хранения и поиска документов\n",
    "\n",
    "    Args:\n",
    "        port (str): Порт для подключения к локальному серверу Weaviate\n",
    "        grpc_port (str): gRPC-порт для подключения к серверу Weaviate\n",
    "        mapping_types (dict): Словарь, описывающий структуру данных коллекции. \n",
    "    Ключи — имена полей, значения — типы данных (например, wc.DataType.TEXT).\n",
    "\n",
    "    Returns:\n",
    "        bool: Возвращает True, если коллекция успешно создана, и False в случае ошибки\n",
    "    \"\"\"\n",
    "    \n",
    "    # Создаём подключение\n",
    "    with weaviate.connect_to_local(\n",
    "       port=port, \n",
    "       grpc_port=grpc_port\n",
    "       ) as client:\n",
    "       \n",
    "        client.collections.delete_all()\n",
    "        collection = client.collections.create(\n",
    "            name='load_data_from_file',\n",
    "            properties=[\n",
    "                wc.Property(\n",
    "                    name=column_name,\n",
    "                    data_type=mapping_types[column_name]\n",
    "                    ) for column_name in mapping_types\n",
    "            ],\n",
    "            \n",
    "            vectorizer_config=wc.Configure.Vectorizer.none(),\n",
    "            # Настройка hnsw\n",
    "            vector_index_config=wc.Configure.VectorIndex.hnsw(\n",
    "                distance_metric=wc.VectorDistances.COSINE,\n",
    "                ef_construction=256,    \n",
    "                max_connections=128,    \n",
    "                quantizer=wc.Configure.VectorIndex.Quantizer.bq(), \n",
    "                ef=-1,                  \n",
    "                dynamic_ef_factor=15,   \n",
    "                dynamic_ef_min=200,     \n",
    "                dynamic_ef_max=1000 \n",
    "            ),\n",
    "            # Настройка полнотекстового поиска\n",
    "            inverted_index_config=wc.Configure.inverted_index(\n",
    "                stopwords_additions=list(STOPWORDS_RUSSIAN),\n",
    "                stopwords_preset=StopwordsPreset.NONE\n",
    "            )\n",
    "        )\n",
    "        \n",
    "setup_search_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разберём приведённый код поподробнее:\n",
    "\n",
    "**Блок кода 1**  \n",
    "\n",
    "```python\n",
    "wc.Configure.Vectorizer.none()\n",
    "```\n",
    "\n",
    "Указывает, что векторизация данных не будет выполняться на стороне Weaviate\n",
    "\n",
    "**Блок кода 2**  \n",
    "\n",
    "Настройка HNSW (Hierarchical Navigable Small World) индекса для векторного поиска. Этот индекс используется для быстрого поиска ближайших соседей \n",
    "\n",
    "![HNSW](img/HNSW.svg)\n",
    "\n",
    "```python\n",
    "vector_index_config=wc.Configure.VectorIndex.hnsw(\n",
    "                distance_metric=wc.VectorDistances.COSINE,\n",
    "                ef_construction=256,    \n",
    "                max_connections=128,    \n",
    "                quantizer=wc.Configure.VectorIndex.Quantizer.bq(), \n",
    "                ef=-1,                  \n",
    "                dynamic_ef_factor=15,   \n",
    "                dynamic_ef_min=200,     \n",
    "                dynamic_ef_max=1000 \n",
    "            )\n",
    "```\n",
    "В этой реализации мы указываем следущие параметры:\n",
    "\n",
    "- Явно указываем метрику расстояния для поиска\n",
    "- Размер динамического списка ближайших соседей при построении индекса. *(Большие значения повышают точность, но увеличивают время построения ef_construction)*\n",
    "- Максимальное кол-во связей для каждой вершины в графе. *(Чем больше связей, тем ваше точность, но тем больше памяти потребуется max_connections)*\n",
    "- Размер динамического списка при поиске. *(В нашем случае -- автоматическое определение размера ef)*\n",
    "\n",
    "\n",
    "**Блок кода 3**\n",
    "\n",
    "Настройка полнотекстового поиска и использованием инвертированного индекса\n",
    "\n",
    "```python\n",
    "inverted_index_config=wc.Configure.inverted_index(\n",
    "                stopwords_additions=list(STOPWORDS_RUSSIAN),\n",
    "                stopwords_preset=StopwordsPreset.NONE\n",
    "            )\n",
    "```\n",
    "\n",
    "Параметры:\n",
    "\n",
    "- stopwords_additions -- Дополнительные стоп-слова на русском языке, которые будут исключены из индексации (Дополнительно указываем, что будем использовать только пользовательские стоп-слова)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl http://localhost:8083/v1/schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение индекса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from weaviate.util import generate_uuid5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_weaviate(\n",
    "    docs: List[Document], \n",
    "    embeddings: List[List[float]],\n",
    "    port: str = '8083',\n",
    "    grpc_port: str = '50051',\n",
    "    collection_name: str = 'load_data_from_file',\n",
    ") -> None:\n",
    "    \n",
    "    # Создаём подключение\n",
    "   with weaviate.connect_to_local(\n",
    "       port=port, \n",
    "       grpc_port=grpc_port\n",
    "       ) as client:\n",
    "       \n",
    "       collection = client.collections.get(collection_name)\n",
    "       with collection.batch.dynamic() as batch:\n",
    "           for doc, embedding in zip(docs, embeddings):\n",
    "               data = {\n",
    "                   'text': doc.page_content,\n",
    "                   'doc_id': doc.metadata['doc_id']\n",
    "               }\n",
    "               obj_uuid = generate_uuid5(doc.metadata[\"doc_id\"])\n",
    "               \n",
    "               batch.add_object(\n",
    "                    properties=data,\n",
    "                    uuid=obj_uuid,\n",
    "                    vector=embedding\n",
    "               )\n",
    "               \n",
    "               if len(collection.batch.failed_objects) > 0:\n",
    "                   raise RuntimeError('Вставка объектов закончилась неудачей((')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\Documents\\GitHub\\llamaindex_RAG_MLLM\\.venv\\Lib\\site-packages\\pydantic\\main.py:214: ResourceWarning: unclosed <socket.socket fd=5260, family=23, type=1, proto=0, laddr=('::1', 59502, 0, 0), raddr=('::1', 11437, 0, 0)>\n",
      "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "fill_weaviate(\n",
    "    docs=split_docs,\n",
    "    embeddings=embeddings_docs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Запуск RAG локально (Бой)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам осталось несколько шагов для построения полной RAG системы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "# from llama_index.llms.ollama import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'привет мир'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вспомним функию для очистки текста\n",
    "text_clean('ПриВет мИр !!! _!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём клиент для работы с LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Россия является одним из самых значимых и важных государств в мире на несколько причин:\n",
      "\n",
      "1. Власть: Россия имеет мощное военное государство, которое отвечает за все государственные задачи, от защиты страны до обеспечения безопасности.\n",
      "\n",
      "2. Страны-военщины: Москва обладает огромным количеством военнослужащих и боевых действующих, что позволяет выполнять важные военные операции.\n",
      "\n",
      "3. Влияние на мир: Россию часто считают важной для мира и безопасности, особенно во время военных или внутренних экономических разногласий.\n",
      "\n",
      "4. Культура: Россия известна своим богатым творческим импровизированием и культурой.\n",
      "\n",
      "5. Величия: Москва занимает важную позицию во многих международных организациях.\n",
      "\n",
      "6. История: Россия имеет долгую историю как национальной, так и культурного, и этот опыт может быть достоверно полезен для других стран.\n",
      "\n",
      "7. Заказы: Москва и другие страны-производители товаров и услуг часто приглашают экспорт, что приводит к глобальному влиянию на экономику и политику многих стран мира.\n",
      "\n",
      "8. Социальная: Москва известна своей значимостью для слоёва населения и социальной жизни, что также может быть полезно для других стран.\n",
      "\n",
      "Однако стоит помнить, что это не все причины объединения России с другими странами. Важно изучать и анализировать конкретные факторы для более точного оценки.\n"
     ]
    }
   ],
   "source": [
    "llm = OllamaLLM(\n",
    "       model='qwen2.5:0.5b',\n",
    "       base_url=\"http://localhost:11437\",\n",
    ")\n",
    "\n",
    "# Напишем запрос к модели\n",
    "prompt = \"\"\"\n",
    "Привет! Почему Россия лучшая страна?\n",
    "\"\"\"\n",
    "\n",
    "# mesage = llm.complete(prompt)\n",
    "\n",
    "print(llm.invoke(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём клиент для работы с векторизацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.024333974, 0.027174825, -0.0067018764, 0.014657992, -0.095907025, -0.085999474, 0.13963348, 0.01984035, -0.010825936, 0.027281752, 0.07512576, -0.14539377, 0.022449352, -0.02175226, 0.07165339, -0.022190709, -0.0020747203, -0.098937556, -0.051401973, -0.024702994, 0.002016932, -0.026661372, -0.018259509, -0.018064039, 0.031074664, -0.02545282, -0.08748126, -0.004877896, 0.08325033, 0.008110117, 0.05884749, 0.024842786, 0.05521977, 0.04374893, 0.004295327, 0.06872931, 0.024665283, -0.016006663, -0.019855365, -0.026829446, -0.056481075, 0.049340934, 0.041310415, 0.026991453, -0.001221893, -0.028030988, -0.019083964, -0.017961057, 0.027202941, -0.02017694, -0.016473884, -0.07783997, -0.057090897, -0.0043340763, 0.06539574, -0.02469487, 0.040410683, 0.015415137, -0.049653236, 0.0234235, 0.028451215, -0.042905852, -0.12578513, 0.021486547, -0.023956237, 0.05465443, -0.032857552, 0.0455701, 0.022862364, 0.012086024, 0.0065209917, -0.05922973, -0.050160006, 0.077816814, 0.0079791555, -0.033807583, 0.050825976, -0.020303398, 0.016429162, -0.022937942, 0.020625226, -0.028771315, -0.02217608, 0.042364433, -0.008777898, -0.008326032, 0.020227423, -0.0042186063, 0.026608508, 0.021902427, 0.0007066179, -0.020788897, -0.009086234, 0.026507638, 0.047400706, -0.020005979, 0.021340724, -0.05125822, 0.07295761, 0.3066792, 0.05158056, 0.008657246, -0.016414165, 0.045596648, -0.006750008, 0.026980946, 0.0072696456, 0.035169393, 0.044893946, 0.028246881, -0.055181924, -0.030843357, 0.007465477, -0.014899887, -0.022645788, 0.004790909, -0.04079522, 0.014228329, -0.031705517, 0.03948744, 0.0240491, -0.0005886786, 0.0023448197, -0.0112027805, 0.054714646, -0.08588499, 0.04125194, -0.0076184203, 0.022750283, 0.0027176219, 0.079407886, 0.06310032, 0.01073499, 0.064545676, -0.0371928, -0.009926789, 0.09206288, 0.0019241795, 0.012242817, -0.021122338, -0.0049279574, 0.030745225, 0.025976328, -0.056386214, -0.08783277, 0.08500368, -0.0022115407, -0.019396856, -0.02658736, -0.014408831, 0.050850794, -0.018367652, -0.00093885895, 0.05128857, 0.005025048, 0.011024254, 0.018148761, -0.010827458, 0.0062794853, 0.0046951277, -0.0042431434, -0.0139922695, -0.008255839, -0.03660872, 0.03717929, -0.040836487, -0.077450134, -0.01836319, -0.0046157204, 0.047015592, -0.061715335, 0.01244552, 0.05198381, 0.004744575, 0.041872006, -0.008218817, -0.032566775, 0.0034311754, -0.04644365, -0.066170365, 0.0804407, 0.023397166, 0.002329923, 0.077693075, -0.033078827, -0.037241407, -0.07622183, -0.025384963, 0.067249425, -0.10083603, 0.012193546, -0.011151489, 0.033792168, -0.04251619, 0.0028829381, -0.08345797, -0.05890227, -0.0017478945, 0.0483195, 0.0006384126, -0.009461735, -0.007592603, 0.009659277, -0.022903156, 0.0600694, 0.032429945, 0.035550795, 0.026537929, 0.027384551, -0.022564307, -0.053012673, -0.003194239, 0.0027537222, 0.0055942424, 0.02845807, -0.063895, -0.06475358, 0.048093777, -0.09284814, 0.008059442, 0.032889508, -0.033843312, -0.039089993, -0.17366222, 0.012800003, 0.06283204, -0.15231872, -0.077999495, -0.006705678, -0.044469938, -0.04264646, 0.02726235, 0.050668444, 0.050223395, -0.010495155, 0.0149569195, 0.100650914, 0.02916167, -0.06271493, -0.07733917, 0.081067465, -0.038571753, -0.07797358, 0.03512116, -0.047533926, -0.015935872, -0.13093318, 0.05364611, -0.035166826, 0.100313365, 0.039412707, 0.02344839, -0.027962279, -0.0056692883, 0.027364995, 0.08498713, 0.0151218735, -0.026777213, 0.0105551155, 0.006594356, 0.00012777711, -0.024176303, -0.057281572, -0.055472113, 0.034957573, -0.0027239707, -0.09641649, 0.09642821, -0.011134483, 0.02235073, -0.04295622, 0.019361544, 0.034759045, -0.0436806, 0.036597595, -0.061747488, 0.093515895, -0.03163773, 0.043177787, 0.0377372, -0.10253478, -0.059626404, -0.017260242, 0.008662548, -0.007286314, -0.0025230881, 0.001220583, 0.11437623, -0.118885644, 0.0075588813, -0.0013877786, 0.04774064, -0.015240763, 0.027695106, 0.022458715, -0.053347666, -0.060464542, -0.03416288, -0.036697734, 0.051934917, 0.022532407, -0.044500466, 0.028500382, -0.013126484, 0.009330407, -0.08760159, 0.044769622, -0.012242304, 0.04856628, -0.0936641, 0.016595205, 0.028084802, 0.0014367341, -0.04171084, -0.065600045, 0.032220874, -0.15683734, -0.025063407, -0.043543898, -0.15365931, 0.001361854, -0.048792202, -0.013605505, 0.048799153, 0.019979268, 0.0011357333, 0.10226322, -0.019010745, 0.0059262044, 0.0072806375, -0.08140414, 0.06924298, -0.021592494, -0.035311464, 0.04819179, 0.054270826, -0.041377723, -0.017816268, -0.019027723, 0.04364797, 0.08892202, 0.04597588, -0.03965892, -0.04950453, -0.038908284, 0.00025983137, 0.02837565, -0.07334496, 0.019088963, 0.08621308, 0.03598316, 0.03193382, -0.017666174, -0.048988823, -0.08476209, 0.019173142, 0.0071797525, 0.03363666, 0.07086419, 0.04486745, 0.022732928, 0.09204277, 0.06637441, 0.118803404, -0.037316743, 0.0376737, 7.9918565e-05, 0.031227907, 0.026249118, -0.018877884, -0.023458062, 0.010203296, 0.020093929, -0.031679776, -0.0020200983, 0.008186213, 0.011516194, 0.075689025, -0.0923087, 0.052292693, 0.03365458, -0.018064728, 0.024482496, 0.05948898]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = OllamaEmbeddings(\n",
    "# vectorizer = OllamaEmbedding(\n",
    "    model='nextfire/paraphrase-multilingual-minilm',\n",
    "    base_url=\"http://localhost:11437\",\n",
    ")\n",
    "\n",
    "\n",
    "print(list(vectorizer.embed_query(\"What is the meaning of life?\")))\n",
    "# print(list(vectorizer.get_general_text_embedding(\"What is the meaning of life?\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем сохранять промпты в созданную папку - prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Создаем директорию для хранения файлов с шаблонами, если она не существует\n",
    "os.makedirs('prompts', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(\n",
    "    path_to_prompt_file: str,\n",
    "    in_vars: List[str]\n",
    ")-> PromptTemplate:\n",
    "    \"\"\"Загружает шаблон из файла\n",
    "\n",
    "    Args:\n",
    "        path_to_prompt_file (str): Путь к файлу\n",
    "        in_vars (List[str]): Список перменных используемых в шаблоне\n",
    "\n",
    "    \"\"\"\n",
    "    return PromptTemplate.from_file(\n",
    "        template_file=path_to_prompt_file,\n",
    "        input_variables=in_vars,\n",
    "        encoding='UTF-8'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаём ретривер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_weaviate.vectorstores import WeaviateVectorStore\n",
    "from langchain_core.vectorstores.base import VectorStoreRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from langchain_weaviate.vectorstores import WeaviateVectorStore\n",
    "# # from langchain_core.vectorstores.base import VectorStoreRetriever\n",
    "\n",
    "\n",
    "# from llama_index.vector_stores.weaviate import WeaviateVectorStore\n",
    "# from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "# # from llama_index.query_engine import RetrieverQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_retriever(\n",
    "    port: str = '8083',\n",
    "    grpc_port: str = '50051',\n",
    "    collection_name: str = 'load_data_from_file',\n",
    "    text_field_for_search: str = 'text',\n",
    "    embeddings_model = vectorizer,\n",
    "    attributes: List[str] = ['doc_id', 'text']\n",
    ") -> VectorStoreRetriever:\n",
    "    \"\"\"Создает ретривер на основе LlamaIndex с Weaviate векторным хранилищем\n",
    "    \"\"\"\n",
    "    \n",
    "    # Подключение к Weaviate\n",
    "    weaviate_client = weaviate.connect_to_local(\n",
    "        port=port,\n",
    "        grpc_port=grpc_port,\n",
    "    )\n",
    "    \n",
    "    # Создаем WeaviateVectorStore\n",
    "    vector_store  = WeaviateVectorStore(\n",
    "        client=weaviate_client,\n",
    "        index_name=collection_name,\n",
    "        text_key=text_field_for_search,\n",
    "        attributes=attributes,\n",
    "        embedding=embeddings_model\n",
    "    )\n",
    "    \n",
    "    # Создаем ретривер на основе векторного хранилища\n",
    "    retriever = vector_store.as_retriever(\n",
    "       search_type=\"similarity\",\n",
    "       search_kwargs={'k': 3}\n",
    "    )\n",
    "    \n",
    "    # # Создаем QueryEngine для выполнения запросов\n",
    "    # query_engine = RetrieverQueryEngine(retriever=retriever)\n",
    "    \n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'doc_id': 'А-05м-23 Гольцов МН КП_v1.pdf'}, page_content='ло полезным инструментом для принятия обоснованных инвестиционных решений в условиях высокой волатильности рынка таким образом результаты данной работы подчеркивают важность адаптивного подхода к моделированию опционов и его применения в практике финансового анализа и управления рисками'),\n",
       " Document(metadata={'doc_id': 'Rebecca_Elliott_-_Painless_Grammar_1997.pdf'}, page_content='25 regular 32 split infinitives 26 subject agreement 155163 subjunctive mood 3031 tenses 2325 voice active versus passive 2628 w waiting on for 196 weights numbers 139 well good 186 which that 196198 which who 198 who whom 198199 why how come what for 199200 words omitted 219220 commas 91 overused 221222 selection 250252 unnecessary 215219 247 usage 173210 xyz you 21 previous page page 264'),\n",
       " Document(metadata={'doc_id': 'Лабораторная работа_Руководство FPTL.pdf'}, page_content='1 c nil c nil 1 c cons args 1 3 fpredicate 1 2 3 filter c cons 2 3 filter args 1 c cons 2 возвращает опорный элемент первый в списке pivot id c cons 1 concat 1 c nil 2 2 c nil 1 1 c cons 1 1 c cons 2 2 concat c cons application listqsort')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = create_retriever()\n",
    "\n",
    "retriever.invoke('Расскажи про модель опционов Блека-Шоулза')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Созадаим цепочку процессов которые будут формировать вывод к нашему приложению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_18744\\1161606906.py:12: DeprecationWarning: `input_variables' is deprecated and ignored.\n",
      "  return PromptTemplate.from_file(\n"
     ]
    }
   ],
   "source": [
    "def chain(\n",
    "    llm: Ollama,\n",
    "    retriever: VectorStoreRetriever,\n",
    "    format_text: Callable,\n",
    "    prompt: PromptTemplate\n",
    ") -> str:\n",
    "    return (\n",
    "        {'context': retriever, 'query': RunnablePassthrough() | format_text}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "\n",
    "rag_chain = chain(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    format_text=text_clean,\n",
    "    prompt = get_prompt(\n",
    "        path_to_prompt_file='prompts/ollama_prompt.txt',\n",
    "        in_vars=['query', 'context']\n",
    "    )        \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Контекст содержит информацию о ф-ции FPTL, которая является частью стандартной пакетной инструментарии Python. Ф-ция FPTL используется для быстрой и удобной построения и отслеживания опорных элементов в списке.\n",
      "\n",
      "В контексте документа 1 \"Лабораторная работа_Руководство FPTL.pdf\", мы видим, что ф-ция FPTL предназначена для быстрого и эффективного отслеживания опорных элементов в списке. Она также предоставляет функции для подсчета количества элементов в списке и обновления списка опорных элементов.\n",
      "\n",
      "В контексте документа 2 \"Rebecca_Elliott_-_Painless_Grammar_1997.pdf\", мы видим, что ф-ция FPTL используется для быстрой построения и отслеживания опорных элементов в списке. Она позволяет быстро находить первый независимый элемент списка.\n",
      "\n",
      "В контексте документа 3 \"Лабораторная работа_Руководство FPTL.pdf\", мы видим, что ф-ция FPTL используется для быстрой и эффективной построения и отслеживания опорных элементов в списке. Она также предоставляет функции для подсчета количества элементов в списке и обновления списка опорных элементов.\n",
      "\n",
      "В контексте документа 4 \"Лабораторная работа_Руководство FPTL.pdf\", мы видим, что ф-ция FPTL используется для быстрой и эффективной построения и отслеживания опорных элементов в списке. Она также предоставляет функции для подсчета количества элементов в списке и обновления списка опорных элементов.\n",
      "\n",
      "Эти данные указывают на то, что ф-ция FPTL является частью стандартной пакетной инструментарии Python и может быть использована в различных задачах, связанных с построением и отслеживанием опорных элементов."
     ]
    }
   ],
   "source": [
    "for chunk in rag_chain.stream(\"Что ты знаешь о FTPL\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Да, в FPTL (Фондовые Техники и Принятие Оптимизированных решения) есть возможности использования функций принимающих один из параметров другого функции. Эти функции обычно называются \"функционалами\" или \"представлениями\", которые позволяют вычислять значения или результаты в зависимости от определенных условий.\n",
      "\n",
      "В Document(metadata={'doc_id': 'Лабораторная работа_Руководство FPTL.pdf'}, page_content='1 c nil c nil 1 c cons args 1 3 fpredicate 1 2 3 filter c cons 2 3 filter args 1 c cons 2') можно прочитать, что в FPTL руководстве приведены правила, которые позволяют определить, какая функция будет работать с инструментом. Например, если у инструмента есть функция `a`, то она может быть использована для расчета значения `b` из функции `f`. Аналогично, если у инструмента есть функция `x`, то она может быть использована для расчета значения `y` из функции `g`.\n",
      "\n",
      "Эти функции позволяют использовать различные подходы и агрегатные методы в работе с данными, что позволяет вычислять результаты эффективнее, чем быстрее и удобнее."
     ]
    }
   ],
   "source": [
    "for chunk in rag_chain.stream(\"В FPTL есть возможность использования функционалов - функций, принимающих в качестве одного из параметров другую функцию\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какие выводы можо сделать по проведённой работе?)\n",
    "\n",
    "Я думаю итог можно поделить на 2 типа:\n",
    "\n",
    "1 - Положительный \n",
    "- Я построил RAG систему 😄\n",
    "- Получил опыт работы с наиболее популярными библиотеками для работы с LLM (langchain, llama_index)\n",
    "- Интегрировал и настроил векторную базу данных (Weaviate)\n",
    "- Поработал с моделью - Qwen-2.5\n",
    "\n",
    "2 - То на что стоит обратить внимание\n",
    "- В приведённом коде достаточно, много всяких рычажков, которые можно покрутить))\n",
    "    - Настройки llm (температура, top-k, top-p)\n",
    "    - Настройки поисковика (Дополнительно опробовать алгоритмы поиска, связанные с деревьями, хешированием)\n",
    "    - Настроить и покрутить промпт\n",
    "\n",
    "- В потенциальном развитии возможно расширить RAG добавив:\n",
    "    - Классификатор вопросов\n",
    "    - Маршрутизатор\n",
    "    - Агентную систему\n",
    "    - Добавить возможность сверять вопрос и ответ с помощью Cross-Encoder или Bi-Encoder\n",
    "\n",
    "*Часть из этих затей планируется опробовать в других проектах*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
